{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e73944c6-10dc-4bf9-a435-fccc27cb8360",
   "metadata": {},
   "source": [
    "# Fine -Tuning Neural Network Hyperparamters"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c79b71fb-a7d6-47a5-8719-11f081904b9f",
   "metadata": {},
   "source": [
    "✅ Learning Rate (step size for weight updates)\n",
    "✅ Batch Size (number of samples per update)\n",
    "✅ Number of Layers & Neurons (network depth & width)\n",
    "✅ Activation Functions (ReLU, Sigmoid, etc.)\n",
    "✅ Dropout Rate (regularization to prevent overfitting)\n",
    "✅ Optimizer Choice (Adam, SGD, RMSprop, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a59d32-9bb1-4040-a96b-61519be4495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04916c63-ca6b-47a9-aad8-f81ce8da00f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    for i in range(hp.Int(\"num_layers\",1, 3)):\n",
    "        model.add(Dense(units = hp.Int(f\"units_{i}\",min_value=32,max_value=256,step=32),\n",
    "                       activation = \"relu\"))\n",
    "        model.add(Dropout(rate=hp.Float(f\"dropout_{i}\",0.1,0.5,step = 0.1)))\n",
    "\n",
    "        #output layer\n",
    "        model.add(Dense(1,activation=\"linear\"))\n",
    "\n",
    "        #tune optimizer\n",
    "        model.compile(optimizer=hp.Choice(\"optimizer\",[\"adam\",\"sgd\",\"rmsprop\"]),\n",
    "                     loss=\"mse\",\n",
    "                     metrics = [\"mae\"]\n",
    "                     )\n",
    "        return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d484ed6-381b-40b3-8ae1-39fdb56eabb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective = \"val_mae\",\n",
    "    max_trials = 10,\n",
    "    executions_per_trial = 2,\n",
    "    directory = \"hyper_tuning\",\n",
    "    project_name = \"neural_net_tuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7194b2a1-2ec3-4371-9d26-6728825dbd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6478063-53dc-41a8-8cb2-3592fa3ad830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 16s]\n",
      "val_mae: 0.24481824040412903\n",
      "\n",
      "Best val_mae So Far: 0.24481824040412903\n",
      "Total elapsed time: 00h 02m 38s\n",
      "Best Hyperparamters : {'num_layers': 3, 'units_0': 256, 'dropout_0': 0.30000000000000004, 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "X_train = np.random.rand(1000,10)\n",
    "y_train = np.random.rand(1000,1)\n",
    "\n",
    "tuner.search(X_train,y_train,epochs = 20,validation_split=0.2,batch_size=32)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparamters : {best_hps.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41c268ec-c701-4f49-a146-44f7109a4d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1952 - mae: 0.3583 - val_loss: 0.0847 - val_mae: 0.2488\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0991 - mae: 0.2686 - val_loss: 0.0857 - val_mae: 0.2483\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0978 - mae: 0.2642 - val_loss: 0.0846 - val_mae: 0.2479\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1002 - mae: 0.2697 - val_loss: 0.0833 - val_mae: 0.2498\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0933 - mae: 0.2606 - val_loss: 0.0810 - val_mae: 0.2468\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0910 - mae: 0.2563 - val_loss: 0.0822 - val_mae: 0.2464\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0844 - mae: 0.2482 - val_loss: 0.0809 - val_mae: 0.2453\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0883 - mae: 0.2534 - val_loss: 0.0811 - val_mae: 0.2475\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0876 - mae: 0.2515 - val_loss: 0.0809 - val_mae: 0.2466\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0816 - mae: 0.2458 - val_loss: 0.0813 - val_mae: 0.2454\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0854 - mae: 0.2482 - val_loss: 0.0807 - val_mae: 0.2469\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0832 - mae: 0.2470 - val_loss: 0.0810 - val_mae: 0.2469\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0879 - mae: 0.2564 - val_loss: 0.0818 - val_mae: 0.2458\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0903 - mae: 0.2582 - val_loss: 0.0820 - val_mae: 0.2455\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0830 - mae: 0.2452 - val_loss: 0.0806 - val_mae: 0.2459\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0847 - mae: 0.2482 - val_loss: 0.0809 - val_mae: 0.2472\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0871 - mae: 0.2537 - val_loss: 0.0811 - val_mae: 0.2462\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0828 - mae: 0.2469 - val_loss: 0.0814 - val_mae: 0.2463\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0836 - mae: 0.2470 - val_loss: 0.0817 - val_mae: 0.2456\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0854 - mae: 0.2467 - val_loss: 0.0820 - val_mae: 0.2455\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0837 - mae: 0.2491 - val_loss: 0.0842 - val_mae: 0.2511\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0856 - mae: 0.2502 - val_loss: 0.0817 - val_mae: 0.2457\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0803 - mae: 0.2428 - val_loss: 0.0820 - val_mae: 0.2460\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0818 - mae: 0.2442 - val_loss: 0.0820 - val_mae: 0.2471\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0794 - mae: 0.2401 - val_loss: 0.0826 - val_mae: 0.2489\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0810 - mae: 0.2417 - val_loss: 0.0826 - val_mae: 0.2458\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0830 - mae: 0.2483 - val_loss: 0.0831 - val_mae: 0.2463\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0824 - mae: 0.2455 - val_loss: 0.0823 - val_mae: 0.2476\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0789 - mae: 0.2389 - val_loss: 0.0826 - val_mae: 0.2474\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0790 - mae: 0.2398 - val_loss: 0.0878 - val_mae: 0.2509\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0761 - mae: 0.2338 - val_loss: 0.0827 - val_mae: 0.2475\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0766 - mae: 0.2355 - val_loss: 0.0856 - val_mae: 0.2485\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0778 - mae: 0.2366 - val_loss: 0.0826 - val_mae: 0.2464\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0799 - mae: 0.2432 - val_loss: 0.0829 - val_mae: 0.2469\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0782 - mae: 0.2389 - val_loss: 0.0858 - val_mae: 0.2521\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0780 - mae: 0.2359 - val_loss: 0.0887 - val_mae: 0.2553\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0795 - mae: 0.2376 - val_loss: 0.0827 - val_mae: 0.2467\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0758 - mae: 0.2366 - val_loss: 0.0835 - val_mae: 0.2476\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - mae: 0.2444 - val_loss: 0.0837 - val_mae: 0.2487\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0797 - mae: 0.2408 - val_loss: 0.0824 - val_mae: 0.2468\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0756 - mae: 0.2342 - val_loss: 0.0828 - val_mae: 0.2456\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0779 - mae: 0.2356 - val_loss: 0.0828 - val_mae: 0.2460\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0749 - mae: 0.2299 - val_loss: 0.0834 - val_mae: 0.2472\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0750 - mae: 0.2353 - val_loss: 0.0829 - val_mae: 0.2470\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0799 - mae: 0.2412 - val_loss: 0.0833 - val_mae: 0.2459\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0750 - mae: 0.2341 - val_loss: 0.0843 - val_mae: 0.2462\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0732 - mae: 0.2296 - val_loss: 0.0831 - val_mae: 0.2451\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0707 - mae: 0.2244 - val_loss: 0.0825 - val_mae: 0.2454\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0741 - mae: 0.2340 - val_loss: 0.0837 - val_mae: 0.2464\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0780 - mae: 0.2353 - val_loss: 0.0830 - val_mae: 0.2461\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train,y_train,epochs = 50,validation_split=0.2,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6139b1-6fb5-498a-b08e-34767b542c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Correct)",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
