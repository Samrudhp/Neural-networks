{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae078a1-7c03-41d0-ae9a-ac22e43fcc78",
   "metadata": {},
   "source": [
    "#  deep network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a3b6c6-2559-4cb9-968e-9e64989b0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0769e51e-1b26-4733-b91a-1fd38b99a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step \n"
     ]
    }
   ],
   "source": [
    "# Load dataset (handwritten digits)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f575d5b-fc80-4538-8541-65dc641bf4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input data\n",
    "x_train = x_train.reshape(-1, 28*28) / 255.0  # Flatten to 1D\n",
    "x_test = x_test.reshape(-1, 28*28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86fe360f-8fac-4c18-8445-e3e5687e095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654ee99a-8411-40c8-a7c6-417888a9f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weights & Biases\n",
    "np.random.seed(42)\n",
    "weights_1 = np.random.randn(28*28, 128) * 0.01  # Input → Hidden Layer 1\n",
    "bias_1 = np.zeros((1, 128))\n",
    "\n",
    "weights_2 = np.random.randn(128, 64) * 0.01  # Hidden Layer 1 → Hidden Layer 2\n",
    "bias_2 = np.zeros((1, 64))\n",
    "\n",
    "weights_3 = np.random.randn(64, 10) * 0.01  # Hidden Layer 2 → Output\n",
    "bias_3 = np.zeros((1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09293a5d-bc18-4914-ae01-9983664a83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4e6dd0-342e-491f-a525-dda3b4deaa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162366a5-00c2-4e2c-976c-4fc0cc1e8543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.002707791241651848\n",
      "Epoch 2/10, Loss: 0.0007457718243550569\n",
      "Epoch 3/10, Loss: 0.00022550068368956512\n",
      "Epoch 4/10, Loss: 0.000539492553072174\n",
      "Epoch 5/10, Loss: 0.00033017614171527954\n",
      "Epoch 6/10, Loss: 0.000698447287987444\n",
      "Epoch 7/10, Loss: 0.00012354822612908978\n",
      "Epoch 8/10, Loss: 4.8900798292600083e-05\n",
      "Epoch 9/10, Loss: 3.979601965333988e-05\n",
      "Epoch 10/10, Loss: 5.876249570324764e-05\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, x_train.shape[0], batch_size):\n",
    "        X_batch = x_train[i:i+batch_size]\n",
    "        Y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "        # Forward Propagation\n",
    "        hidden_1_input = np.dot(X_batch, weights_1) + bias_1\n",
    "        hidden_1_output = relu(hidden_1_input)\n",
    "\n",
    "        hidden_2_input = np.dot(hidden_1_output, weights_2) + bias_2\n",
    "        hidden_2_output = relu(hidden_2_input)\n",
    "\n",
    "        final_input = np.dot(hidden_2_output, weights_3) + bias_3\n",
    "        final_output = softmax(final_input)\n",
    "\n",
    "        # Compute Loss (Cross-Entropy)\n",
    "        loss = -np.mean(Y_batch * np.log(final_output + 1e-8))\n",
    "\n",
    "        # Backpropagation\n",
    "        error_output = final_output - Y_batch\n",
    "        d_weights_3 = np.dot(hidden_2_output.T, error_output)\n",
    "        d_bias_3 = np.sum(error_output, axis=0, keepdims=True)\n",
    "\n",
    "        error_hidden_2 = np.dot(error_output, weights_3.T) * relu_derivative(hidden_2_output)\n",
    "        d_weights_2 = np.dot(hidden_1_output.T, error_hidden_2)\n",
    "        d_bias_2 = np.sum(error_hidden_2, axis=0, keepdims=True)\n",
    "\n",
    "        error_hidden_1 = np.dot(error_hidden_2, weights_2.T) * relu_derivative(hidden_1_output)\n",
    "        d_weights_1 = np.dot(X_batch.T, error_hidden_1)\n",
    "        d_bias_1 = np.sum(error_hidden_1, axis=0, keepdims=True)\n",
    "\n",
    "        # Update Weights & Biases\n",
    "        weights_1 -= learning_rate * d_weights_1\n",
    "        bias_1 -= learning_rate * d_bias_1\n",
    "\n",
    "        weights_2 -= learning_rate * d_weights_2\n",
    "        bias_2 -= learning_rate * d_bias_2\n",
    "\n",
    "        weights_3 -= learning_rate * d_weights_3\n",
    "        bias_3 -= learning_rate * d_bias_3\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abdd263a-85ed-4fc8-9638-b0b52e96bd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.01%\n"
     ]
    }
   ],
   "source": [
    "# Test Accuracy\n",
    "hidden_1_test = relu(np.dot(x_test, weights_1) + bias_1)\n",
    "hidden_2_test = relu(np.dot(hidden_1_test, weights_2) + bias_2)\n",
    "final_test = softmax(np.dot(hidden_2_test, weights_3) + bias_3)\n",
    "\n",
    "accuracy = np.mean(np.argmax(final_test, axis=1) == np.argmax(y_test, axis=1))\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e900c8-6445-449a-ada3-626d6f1f7c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Correct)",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
